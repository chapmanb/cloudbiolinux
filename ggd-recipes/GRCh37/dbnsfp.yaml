# google drive downloads are unreliable - too many requests, try again in 24h
# using ftp ftp://dbnsfp:dbnsfp@dbnsfp.softgenetics.com/dbNSFP4.1a.zip
# bumped version because 3.5a is not supported anymore - 25G instead of 16G
---
attributes:
  name: dbnsfp
  version: 4.1a
recipe:
  full:
    recipe_type: bash
    recipe_cmds:
      - |
        mkdir -p variation
        cd variation
        wget -c ftp://dbnsfp:dbnsfp@dbnsfp.softgenetics.com/dbNSFP4.1a.zip
        UNPACK_DIR=`pwd`/tmpunpack
        if [ ! -f dbNSFP.txt.gz ]; then
          mkdir -p $UNPACK_DIR
          unzip dbNSFP*.zip "dbNSFP*_variant.chrM.gz"
          gunzip dbNSFP*_variant.chrM.gz
          head -n1 dbNSFP*_variant.chrM | head -n1 > $UNPACK_DIR/header.txt
          rm dbNSFP*_variant.chrM
          # unzip only files with chromosomal info, eg. skip genes and readme.
          # [awk] check if hg19 position exists, if so, move data to col 1 and 2, then print
          # and sort on first and second column
          unzip -p dbNSFP*.zip "dbNSFP*_variant.chr*" | gunzip -c | grep -v '^#chr' | awk -F $'\t' 'BEGIN {OFS = FS} {if ($8 != "." && $9 != ".") {$1=$8;$2=$9;print}}' | sort -T $UNPACK_DIR -k1,1 -k2,2n | cat $UNPACK_DIR/header.txt - | bgzip -c > dbNSFP.txt.gz
          #extract readme file, used by VEP plugin to add vcf header info
          unzip -p dbNSFP*.zip "*readme.txt" > dbNSFP.readme.txt
        fi
        # index in position 1 and 2
        tabix -f -s 1 -b 2 -e 2 -c '#' dbNSFP.txt.gz
        rm -f $UNPACK_DIR/* && rmdir $UNPACK_DIR
        rm -f dbNSFP*.zip
    recipe_outfiles:
      - variation/dbNSFP.txt.gz
      - variation/dbNSFP.txt.gz.tbi
      - variation/dbNSFP.readme.txt
